{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331a96ad-a0a9-4cc4-87e3-526ac7f9d485",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ecb1bc-1e78-4a4d-a5f0-6c6deb5e84a6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "session_starting",
       "parent_msg_id": "0be10c6b-a010-4f2d-9e48-d43c79872c05",
       "queued_time": "2025-04-28T21:02:39.6899862Z",
       "session_id": null,
       "session_start_time": "2025-04-28T21:02:39.6910626Z",
       "spark_pool": null,
       "state": "session_starting",
       "statement_id": -1,
       "statement_ids": []
      },
      "text/plain": [
       "StatementMeta(, , -1, SessionStarting, , SessionStarting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import logging\n",
    "\n",
    "from typing import List, Any\n",
    "from delta import DeltaTable\n",
    "from pyspark.sql import DataFrame, Row\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d30fc-3d44-4090-97b5-f0cf8acbf525",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Setup and initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f841f-ff74-4a04-8e89-ed874bb3e68e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "410adcd8-5b09-46b4-bddb-9b8716f4148e",
       "queued_time": "2025-04-28T21:02:39.6923807Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Google-Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3fd152-703e-4341-ba8d-e6994e8abe41",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "68a5a5c1-dfa1-48e1-8f08-cf4fa7637db3",
       "queued_time": "2025-04-28T21:02:39.694505Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Youtube API\n",
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "DEVELOPER_KEY = \"\"\n",
    "\n",
    "# Delta table names\n",
    "VIDEOS_TABLE = \"abfss://fd12376e-2797-4027-bb8e-42a3a8228a70@onelake.dfs.fabric.microsoft.com/77b89b44-1bcf-42fa-a9ac-7d0593123d3d/Tables/videos\"\n",
    "PLAYLISTS_TABLE = \"abfss://fd12376e-2797-4027-bb8e-42a3a8228a70@onelake.dfs.fabric.microsoft.com/77b89b44-1bcf-42fa-a9ac-7d0593123d3d/Tables/playlists\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a71b8-4efa-4393-86c9-9101854af594",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "ca8f1adc-c808-4175-a93a-9188180fef0b",
       "queued_time": "2025-04-28T21:02:39.697042Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = setup_logger()\n",
    "youtube_client = build_youtube_client(API_SERVICE_NAME,API_VERSION,DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b2859-1dcd-40ea-9780-bd5bc35fef52",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30bd52-1394-4db3-8d86-9f5e41fd1f01",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "3d501f24-4ecd-4bd9-8847-452e2935564c",
       "queued_time": "2025-04-28T21:02:39.6991453Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_schema = T.StructType([\n",
    "    T.StructField(\"id\", T.StringType(), True),\n",
    "    T.StructField(\"title\", T.StringType(), True),\n",
    "    T.StructField(\"playlistId\", T.StringType(), True)\n",
    "])\n",
    "\n",
    "details_schema = T.StructType([\n",
    "    T.StructField(\"videoId\", T.StringType(), True),\n",
    "    T.StructField(\"viewCount\", T.IntegerType(), True),\n",
    "    T.StructField(\"likeCount\", T.IntegerType(), True),\n",
    "    T.StructField(\"commentCount\", T.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b36d3b-9ecd-4629-a312-7a755bb285bd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "a868aece-e702-43bd-90c0-5324b4fa3b30",
       "queued_time": "2025-04-28T21:02:39.7013109Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_playlists() -> DataFrame:\n",
    "    \"\"\"\n",
    "    Load playlists data from a Delta table.\n",
    "    \n",
    "    Returns:\n",
    "        A DataFrame containing playlists.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Loading playlists data\")\n",
    "        playlists_df = spark.read.format(\"delta\").load(PLAYLISTS_TABLE)\n",
    "        logger.debug(\"Finished loading playlists\")\n",
    "        return playlists_df\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Failed to load playlists data\")\n",
    "        raise\n",
    "\n",
    "playlists = load_playlists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a16a55-b591-4174-9e52-1c6d08af740e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# API Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99db6c-7dce-4f29-b3fb-c072acb3a6ef",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get videos from playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3c184-2481-4b3f-8348-4f68755de296",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "882d49d3-73e0-49d2-a7c1-9afc055dc012",
       "queued_time": "2025-04-28T21:02:39.7035557Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_videos(playlist: Row) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Fetch videos from a given playlist using the YouTube API.\n",
    "    \n",
    "    Args:\n",
    "        playlist: A Row object expected to have attributes `PlaylistId` and `Year`.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing (videoId, title, playlistId).\n",
    "    \"\"\"\n",
    "    playlist_id = playlist.PlaylistId\n",
    "    try:\n",
    "        logger.debug(f\"Loading playlist items for playlist {playlist_id} ({playlist.Year})\")\n",
    "        request = youtube_client.playlistItems().list(\n",
    "            part=\"snippet,contentDetails,status\",\n",
    "            maxResults=50,\n",
    "            playlistId=playlist_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        items = response.get('items', [])\n",
    "        public_items = [d for d in items if d[\"status\"][\"privacyStatus\"] == 'public']\n",
    "        data = [\n",
    "            (\n",
    "                d['snippet']['resourceId']['videoId'],\n",
    "                d['snippet']['title'],\n",
    "                playlist_id\n",
    "            ) for d in public_items\n",
    "        ]\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to load videos for playlist {playlist_id} ({playlist.Year}): {str(e)}\"\n",
    "        logger.exception(error_message)\n",
    "        raise RuntimeError(error_message)\n",
    "\n",
    "def parallel_process(playlists_rdd) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Process the playlists RDD in parallel by fetching videos.\n",
    "    \n",
    "    Args:\n",
    "        playlists_rdd: RDD of playlist rows.\n",
    "        \n",
    "    Returns:\n",
    "        A DataFrame containing video data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        videos_rdd = playlists_rdd.flatMap(lambda playlist: get_videos(playlist))\n",
    "        return spark.createDataFrame(videos_rdd, schema=video_schema)\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error during parallel processing of playlists: {str(e)}\")\n",
    "        raise RuntimeError(\"Parallel processing failed.\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a67a75-987a-41e9-8a1a-f38117b9510d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "bea8ff88-fc3a-4fff-a6c4-f659e71619bf",
       "queued_time": "2025-04-28T21:02:39.7058191Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_df = parallel_process(playlists.rdd)\n",
    "logger.info(f\"Total videos retrieved: {video_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa66f5d-6757-4b07-bff0-061017de0d6d",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Get video details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac9c7e-ac02-45b5-9986-ce9fd6eaeacd",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "58cce3f7-434a-42a5-83fd-2803bc97f51a",
       "queued_time": "2025-04-28T21:02:39.7079363Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fetch_video_details(video_ids: List[str], batch_size: int = 50) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Fetch video details from the YouTube API for the provided video IDs.\n",
    "    \n",
    "    Args:\n",
    "        video_ids: List of video IDs.\n",
    "        batch_size: Number of IDs to process per API call.\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples: (videoId, viewCount, likeCount, commentCount)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    try:\n",
    "        for i in range(0, len(video_ids), batch_size):\n",
    "            batch = video_ids[i:i + batch_size]\n",
    "            logger.debug(\"Fetching video details for a batch\")\n",
    "            request = youtube_client.videos().list(\n",
    "                part=\"statistics\",\n",
    "                id=\",\".join(batch)\n",
    "            )\n",
    "            response = request.execute()\n",
    "            items = response.get('items', [])\n",
    "            results.extend([\n",
    "                (\n",
    "                    d['id'],\n",
    "                    int(d['statistics'].get('viewCount', 0)),\n",
    "                    int(d['statistics'].get('likeCount', 0)),\n",
    "                    int(d['statistics'].get('commentCount', 0))\n",
    "                ) for d in items\n",
    "            ])\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to fetch video details for batch {video_ids}. Error: {str(e)}\"\n",
    "        logger.error(error_message)\n",
    "        raise RuntimeError(error_message)\n",
    "    return results\n",
    "\n",
    "def process_partition(video_ids_partition) -> List[tuple]:\n",
    "    \"\"\"\n",
    "    Process a partition of video IDs and fetch details.\n",
    "    \n",
    "    Args:\n",
    "        video_ids_partition: A partition (iterator) of video IDs.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing video details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        video_ids = list(video_ids_partition)\n",
    "        logger.debug(f\"Processing a partition of {len(video_ids)} video IDs\")\n",
    "        if not video_ids:\n",
    "            return []\n",
    "        return fetch_video_details(video_ids)\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error processing video IDs partition: {str(e)}\")\n",
    "        raise RuntimeError(\"Parallel processing of video details failed.\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49881677-dee5-4669-b877-8983784a698f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "172b9b39-3cca-4176-beb1-c9949db74c43",
       "queued_time": "2025-04-28T21:02:39.7105005Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # Process video details in parallel using RDD\n",
    "    video_ids_rdd = video_df.select(\"id\").rdd.map(lambda row: row.id)\n",
    "    video_details_rdd = video_ids_rdd.mapPartitions(process_partition)\n",
    "    video_details_df = spark.createDataFrame(video_details_rdd, schema=details_schema)\n",
    "\n",
    "    # Join video data with details\n",
    "    joined_df = video_df.join(video_details_df, video_df.id == video_details_df.videoId, \"leftouter\").drop(\"videoId\")\n",
    "    logger.info(f\"Total videos processed with details: {joined_df.count()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Error during parallel processing: {str(e)}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa6bbd-682a-4729-aed1-5cd961425715",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97993bf2-1e07-4632-9832-3b6ec4149dc3",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "e7ce7703-9f40-4f75-b303-22a585d69ff3",
       "queued_time": "2025-04-28T21:02:39.7125962Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def merge_videos_data(joined_df: DataFrame, table_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Merge the joined video data into the Delta table\n",
    "    \n",
    "    Args:\n",
    "        joined_df: The DataFrame containing the new video data and details.\n",
    "        table_path: The Delta table path to merge into.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        target_table = DeltaTable.forPath(spark, table_path)\n",
    "        logger.info(\"Merging data started\")\n",
    "        (\n",
    "            target_table.alias(\"target\").merge(\n",
    "                joined_df.alias(\"source\"),\n",
    "                \"target.id = source.id\"\n",
    "            ).whenMatchedUpdate(set={\n",
    "                \"title\": \"source.title\",\n",
    "                \"playlistId\": \"source.playlistId\",\n",
    "                \"viewCount\": \"source.viewCount\",\n",
    "                \"likeCount\": \"source.likeCount\",\n",
    "                \"commentCount\": \"source.commentCount\",\n",
    "                \"_modified_date\": \"current_timestamp()\"\n",
    "            })\n",
    "            .whenNotMatchedInsert(values={\n",
    "                \"id\": \"source.id\",\n",
    "                \"title\": \"source.title\",\n",
    "                \"playlistId\": \"source.playlistId\",\n",
    "                \"viewCount\": \"source.viewCount\",\n",
    "                \"likeCount\": \"source.likeCount\",\n",
    "                \"commentCount\": \"source.commentCount\",\n",
    "                \"_created_date\": \"current_timestamp()\",\n",
    "                \"_modified_date\": \"current_timestamp()\"\n",
    "            })\n",
    "            .whenNotMatchedBySourceDelete()\n",
    "            .execute()\n",
    "        )\n",
    "        logger.info(\"Merging data finished\")\n",
    "        lastCommit = target_table.history(1).collect()[0]\n",
    "        metrics = lastCommit[\"operationMetrics\"] \n",
    "\n",
    "        numInserted = int(metrics.get(\"numTargetRowsInserted\", 0))\n",
    "        numUpdated = int(metrics.get(\"numTargetRowsUpdated\", 0))\n",
    "        numDeleted = int(metrics.get(\"numTargetRowsDeleted\", 0))\n",
    "\n",
    "        logger.info(f\"Rows inserted: {numInserted}\")\n",
    "        logger.info(f\"Rows updated: {numUpdated}\")\n",
    "        logger.info(f\"Rows deleted: {numDeleted}\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Exception details: %s\", str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307d481-b86d-43b9-b83a-8fca9909297b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": null,
       "execution_start_time": null,
       "livy_statement_state": null,
       "normalized_state": "waiting",
       "parent_msg_id": "a903af82-a758-492a-9c9b-032e234186dd",
       "queued_time": "2025-04-28T21:02:39.7146784Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "waiting",
       "statement_id": -1,
       "statement_ids": null
      },
      "text/plain": [
       "StatementMeta(, , -1, Waiting, , Waiting)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_videos_data(joined_df, VIDEOS_TABLE)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {
    "environmentId": "143044df-8d0d-4272-ae18-32804b812e76",
    "workspaceId": "fd12376e-2797-4027-bb8e-42a3a8228a70"
   },
   "lakehouse": {
    "default_lakehouse": "77b89b44-1bcf-42fa-a9ac-7d0593123d3d",
    "default_lakehouse_name": "Raw",
    "default_lakehouse_workspace_id": "fd12376e-2797-4027-bb8e-42a3a8228a70",
    "known_lakehouses": [
     {
      "id": "77b89b44-1bcf-42fa-a9ac-7d0593123d3d"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
